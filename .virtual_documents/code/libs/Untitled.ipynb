import math
import torch
import torchvision

from torchvision.models import resnet
from torchvision.models.feature_extraction import create_feature_extractor
from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork, LastLevelP6P7
from torchvision.ops.boxes import batched_nms

import torch
from torch import nn



class FCOSClassificationHead(nn.Module):
    """
    A classification head for FCOS with convolutions and group norms

    Args:
        in_channels (int): number of channels of the input feature.
        num_classes (int): number of classes to be predicted
        num_convs (Optional[int]): number of conv layer. Default: 3.
        prior_probability (Optional[float]): probability of prior. Default: 0.01.
    """

    def __init__(self, in_channels, num_classes, num_convs=3, prior_probability=0.01):
        super().__init__()
        self.num_classes = num_classes

        conv = []
        for _ in range(num_convs):
            conv.append(
                nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1)
            )
            conv.append(nn.GroupNorm(16, in_channels))
            conv.append(nn.ReLU())
        self.conv = nn.Sequential(*conv)

        # A separate background category is not needed, as later we will consider
        # C binary classfication problems here (using sigmoid focal loss)
        self.cls_logits = nn.Conv2d(
            in_channels, num_classes, kernel_size=3, stride=1, padding=1
        )
        torch.nn.init.normal_(self.cls_logits.weight, std=0.01)
        # see Sec 3.3 in "Focal Loss for Dense Object Detection'
        torch.nn.init.constant_(
            self.cls_logits.bias, -math.log((1 - prior_probability) / prior_probability)
        )

    def forward(self, x):
        """
        Fill in the missing code here. The head will be applied to all levels
        of the feature pyramid, and predict a single logit for each location on
        every feature location.

        Without pertumation, the results will be a list of tensors in increasing
        depth order, i.e., output[0] will be the feature map with highest resolution
        and output[-1] will the featuer map with lowest resolution. The list length is
        equal to the number of pyramid levels. Each tensor in the list will be
        of size N x C x H x W, storing the classification logits (scores).

        Some re-arrangement of the outputs is often preferred for training / inference.
        You can choose to do it here, or in compute_loss / inference.
        """
        for i in range(len(x)):
            x[i] = self.conv(x[i])
            x[i] = self.cls_logits(x[i])
        
        return x


class FCOSRegressionHead(nn.Module):
    """
    A regression head for FCOS with convolutions and group norms.
    This head predicts
    (a) the distances from each location (assuming foreground) to a box
    (b) a center-ness score

    Args:
        in_channels (int): number of channels of the input feature.
        num_convs (Optional[int]): number of conv layer. Default: 3.
    """

    def __init__(self, in_channels, num_convs=3):
        super().__init__()
        conv = []
        for _ in range(num_convs):
            conv.append(
                nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1)
            )
            conv.append(nn.GroupNorm(16, in_channels))
            conv.append(nn.ReLU())
        self.conv = nn.Sequential(*conv)

        # regression outputs must be positive
        self.bbox_reg = nn.Sequential(
            nn.Conv2d(in_channels, 4, kernel_size=3, stride=1, padding=1),
            nn.ReLU()
        )
        self.bbox_ctrness = nn.Conv2d(
            in_channels, 1, kernel_size=3, stride=1, padding=1
        )

        self.apply(self.init_weights)
        # The following line makes sure the regression head output a non-zero value.
        # If your regression loss remains the same, try to uncomment this line.
        # It helps the initial stage of training
        # torch.nn.init.normal_(self.bbox_reg[0].bias, mean=1.0, std=0.1)

    def init_weights(self, m):
        if isinstance(m, nn.Conv2d):
            torch.nn.init.normal_(m.weight, std=0.01)
            torch.nn.init.zeros_(m.bias)

    def forward(self, x):
        """
        Fill in the missing code here. The logic is rather similar to
        FCOSClassificationHead. The key difference is that this head bundles both
        regression outputs and the center-ness scores.

        Without pertumation, the results will be two lists of tensors in increasing
        depth order, corresponding to regression outputs and center-ness scores.
        Again, the list length is equal to the number of pyramid levels.
        Each tensor in the list will be of size N x 4 x H x W (regression)
        or N x 1 x H x W (center-ness).

        Some re-arrangement of the outputs is often preferred for training / inference.
        You can choose to do it here, or in compute_loss / inference.
        """
        bbox_regression = []
        bbox_ctrness = []
        
        for feature in x:
            out = self.conv(feature)
            bbox_reg = self.bbox_reg(out)
            ctrness = self.bbox_ctrness(out)
            
            bbox_regression.append(bbox_reg)
            bbox_ctrness.append(ctrness)
        
        return bbox_regression, bbox_ctrness




num_classes = 20  # Example: 20 object classes
in_channels = 256  # Example channel size for feature maps
classification_head = FCOSClassificationHead(in_channels, num_classes)
regression_head = FCOSRegressionHead(in_channels)

# Create dummy input for the classification head (20 channels as required)
classification_features = [
    torch.randn(2, in_channels, 64, 64),
    torch.randn(2, in_channels, 32, 32),
    torch.randn(2, in_channels, 16, 16)
]

# Create dummy input for the regression head (256 channels as required)
regression_features = [
    torch.randn(2, 256, 64, 64),
    torch.randn(2, 256, 32, 32),
    torch.randn(2, 256, 16, 16)
]

# Test the classification head
classification_outputs = classification_head(classification_features)
print("Classification Outputs:")
for i, output in enumerate(classification_outputs):
    print(f"Level {i} output shape: {output.shape}")  # Expected: (2, num_classes, H, W) for each level

# Test the regression head
regression_outputs, ctrness_outputs = regression_head(regression_features)
print("\nRegression Outputs:")
for i, output in enumerate(regression_outputs):
    print(f"Level {i} regression output shape: {output.shape}")  # Expected: (2, 4, H, W) for each level

print("\nCenter-ness Outputs:")
for i, output in enumerate(ctrness_outputs):
    print(f"Level {i} center-ness output shape: {output.shape}")  # Expected: (2, 1, H, W) for each level




